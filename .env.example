# Gemini API Configuration
GOOGLE_API_KEY=your_api_key_here

# Set to "true" to use Gemini model, "false" to use Llama
USE_GEMINI=true

# Gemini model version (flash is recommended for faster inference)
GEMINI_MODEL=gemini-2.0-flash-exp
